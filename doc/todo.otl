Test software
	[X] Test Tensorflow with CPU
	[X] Test Tensorflow with GPU
	[X] Test Keras with CPU
	[X] Test Keras with GPU

Copy notebooks
	[X] Copy notebooks to the AWS VM
	[X] Copy notebooks from the AWS VM
	[X] Use rsync to copy code to aws and synchronize to local

Setup software
	[X] Use Deep Learning Base AMI (Ubuntu) 
	[X] Create spot instance with static security group
	[X] Install software with Ansible
	[X] Create security group with script
	[X] Setup storm ssh config
	[X] Add command: ec2 tunnel $INST_ID
	[_] Setup rclone config
	[_] Instead of using scp use rclone and exclude the checkpoints dir

Jupyter notebooks
	[_] Document convolution notebook based on tutorial
		: https://elitedatascience.com/keras-tutorial-deep-learning-in-python
	[_] Setup tmuxp
		: gensim-vm\doc\aws-spot-instance.txt 
	[_] Activate conda env and run jupyter notebook with tmuxp
	[_] Install jupyter_contrib_nbextensions
	[_] Install jupyter vim binding
	[_] Change prices in code/aws_utils.py to U.S. East 2

Investigate Keras data sets
https://keras.io/datasets/

How to setup EBS instances and Jupyter notebooks
https://github.com/PiercingDan/spark-Jupyter-AWS

May need to wait for
https://github.com/ansible/ansible/issues/16593

- name: Wait for automatic system updates
  become: yes
  wait_for: path=/var/lib/dpkg/lock state=absent

Need to create a rclone file like this

ubuntu@tensorflow-aws:/vagrant/playbooks$ cat /home/ubuntu/.config/rclone/rclone.conf
[keras-vm]
type = sftp
host = 192.168.3.22
user =
port =
pass =
key_file =
